\section{Introduction}

% GANs
Since their introduction in 2014, Generative Adversarial Networks (GANs) \cite{goodfellow2014generative} have gained a lot of popularity in the machine learning community and more specifically in the field of generative models. The GAN framework has been applied with admirable results to many different applications such as computer vision \cite{DBLP:journals/corr/RadfordMC15} \cite{ledig2016photo} \cite{isola2017image}, speech synthesis \cite{kaneko2017generative} \cite{pascual2017segan}, or drug discovery \cite{guimaraes2017objective}. 

We give a brief overview of the GAN framework. GANs consist of two major components, namely a generator and a discriminator, both consisting of a neural network. The aim of the generator is to generate samples that mimic a real data distribution from noise, and the aim of the discriminator is to distinguish samples that come from the real data distribution from the ones produced by the generator. Trained consecutively as an adversarial pair, these networks will enter a game in which the generator is encouraged to model the real data distribution as closely as possible with the discriminator acting as a critic as accurate as possible. On top of their practical abilities, this makes GANs very interesting for their inherent theoretical aspects, paving the way to leveraging methods and techniques that were formerly used in game theory exclusively.

Now, the training of GANs is an infamously intricate task. In fact, a significant amount of the research on GANs has been focusing on how to improve the stability of their training. More specifically, the performance of the discriminator gets hard to control since the density ratio estimation in high-dimensional spaces is commonly inaccurate and unstable; the generator can then hardly learn the multimodal structure of the target distribution.


% SN
There has been numerous efforts to overcome this stability issue, amongst which expressing the network's objective functions differently, i.e. re-writing the discriminator and generator losses was shown promising. For instance, a different probability distribution divergence measure is proposed with the Wasserstein GAN (WGAN) \cite{arjovsky2017wasserstein}. Another example is the Least Squares GAN (LSGAN), where the vanishing gradient problem of the sigmoid function used in the original GAN is exposed and a solution is proposed by adopting a least squares loss function for the discriminator loss.  

In a different approach, more architectural this time, spectral normalization proposes a method that reduces the function space from which can originate the discriminator to the space of Lipschitz continuous functions, assuring the boundedness of statistics \todo{cite}. This is done by normalizing the weight matrix of each layer using their spectral norm. The authors show that doing so not only improves the stability of the learning, but also that the method is easily implemented and tuned. We describe spectral normalization in more details in Section \ref{sec:bg-sn}. This recent development has received a hugely positive appraisal and is seen by many as a major breakthrough in deep learning.

% Problem statement
In this work, we implement a number of different GANs for image generation and add spectral normalization \cite{miyato2018spectral} to evaluate its effect on all of our configurations. For instance, we try WGAN \cite{arjovsky2017wasserstein}, which works under the assumption that the discriminator function is Lipschitz continuous; a property assured by spectral normalization. In this regard, it makes sense to run experiments on WGAN with spectral normalization or different ways of ensuring the discriminator's Lipschitz continuity. In order to evaluate and compare the performance of our GANs, we use the Inception score \cite{salimans2016improved}. We also discuss the relevance of this metric. As for the datasets, we use CIFAR10 \cite{cifar100} and another dataset that we gathered ourselves for this study consisting of 20K animal pictures (mostly reptiles), fetched from the Flickr API. In the following, we will denote it the ``Reptiles'' dataset. The purpose is to evaluate these techniques on arbitrary data and not the usual computer vision datasets. 

% Expectations